2025-07-15 06:30:38,756 transreid INFO: Saving model in the path :football_output_dir
2025-07-15 06:30:38,756 transreid INFO: Namespace(config_file='configs/person/vit_clipreid.yml', local_rank=0, opts=[])
2025-07-15 06:30:38,756 transreid INFO: Loaded configuration file configs/person/vit_clipreid.yml
2025-07-15 06:30:38,756 transreid INFO: 
MODEL:
  PRETRAIN_CHOICE: 'imagenet'
  METRIC_LOSS_TYPE: 'triplet'
  IF_LABELSMOOTH: 'on'
  IF_WITH_CENTER: 'no'
  NAME: 'ViT-B-16'
  STRIDE_SIZE: [16, 16]
  ID_LOSS_WEIGHT : 0.25
  TRIPLET_LOSS_WEIGHT : 1.0
  I2T_LOSS_WEIGHT : 1.0
  # SIE_CAMERA: True
  # SIE_COE : 1.0

INPUT:
  SIZE_TRAIN: [256, 128]
  SIZE_TEST: [256, 128]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.5 # random erasing
  PADDING: 10
  PIXEL_MEAN: [0.5, 0.5, 0.5]
  PIXEL_STD: [0.5, 0.5, 0.5]

DATALOADER:
  SAMPLER: 'softmax_triplet'
  NUM_INSTANCE: 4
  NUM_WORKERS: 8

SOLVER:
  STAGE1:
    IMS_PER_BATCH: 64
    OPTIMIZER_NAME: "Adam"
    BASE_LR: 0.00035
    WARMUP_LR_INIT: 0.00001
    LR_MIN: 1e-6
    WARMUP_METHOD: 'linear'
    WEIGHT_DECAY:  1e-4
    WEIGHT_DECAY_BIAS: 1e-4
    MAX_EPOCHS: 120 # Reduced from 120
    CHECKPOINT_PERIOD: 120
    LOG_PERIOD: 50
    WARMUP_EPOCHS: 5
  
  STAGE2:
    IMS_PER_BATCH: 64
    OPTIMIZER_NAME: "Adam"
    BASE_LR: 0.00001 # changed from 0.000005
    WARMUP_METHOD: 'linear'
    WARMUP_ITERS: 10
    WARMUP_FACTOR: 0.1
    WEIGHT_DECAY:  0.0001
    WEIGHT_DECAY_BIAS: 0.0001
    LARGE_FC_LR: False
    MAX_EPOCHS: 60 # Reduced from 60
    CHECKPOINT_PERIOD: 5 # Reduced from 60
    LOG_PERIOD: 50
    # EVAL_PERIOD: 60
    EVAL_PERIOD: 5
    BIAS_LR_FACTOR: 2
    
    # STEPS: [30, 50]
    STEPS: [30,50]
    GAMMA: 0.1
  
TEST:
  EVAL: True
  IMS_PER_BATCH: 64
  RE_RANKING: False
  WEIGHT: ''
  NECK_FEAT: 'before'
  FEAT_NORM: 'yes'

DATASETS:
    NAMES: ('sportsmot_football')
    ROOT_DIR: ('datasets')
OUTPUT_DIR: 'football_output_dir'
#   NAMES: ('market1501')
#   ROOT_DIR: ('')
# OUTPUT_DIR: ''

#   NAMES: ('dukemtmc')
#   ROOT_DIR: ('')
# OUTPUT_DIR: ''

#   NAMES: ('occ_duke')
#   ROOT_DIR: ('')
# OUTPUT_DIR: ''

#   NAMES: ('msmt17')
#   ROOT_DIR: ('')
# OUTPUT_DIR: ''

# CUDA_VISIBLE_DEVICES=3 python train_clipreid.py --config_file configs/person/vit_clipreid.yml

2025-07-15 06:30:38,757 transreid INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 8
  SAMPLER: softmax_triplet
DATASETS:
  NAMES: sportsmot_football
  ROOT_DIR: datasets
INPUT:
  PADDING: 10
  PIXEL_MEAN: [0.5, 0.5, 0.5]
  PIXEL_STD: [0.5, 0.5, 0.5]
  PROB: 0.5
  RE_PROB: 0.5
  SIZE_TEST: [256, 128]
  SIZE_TRAIN: [256, 128]
MODEL:
  ATT_DROP_RATE: 0.0
  COS_LAYER: False
  DEVICE: cuda
  DEVICE_ID: 0
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  I2T_LOSS_WEIGHT: 1.0
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 0.25
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LAST_STRIDE: 1
  METRIC_LOSS_TYPE: triplet
  NAME: ViT-B-16
  NECK: bnneck
  NO_MARGIN: False
  PRETRAIN_CHOICE: imagenet
  PRETRAIN_PATH: 
  SIE_CAMERA: False
  SIE_COE: 3.0
  SIE_VIEW: False
  STRIDE_SIZE: [16, 16]
  TRANSFORMER_TYPE: None
  TRIPLET_LOSS_WEIGHT: 1.0
OUTPUT_DIR: football_output_dir
SOLVER:
  MARGIN: 0.3
  SEED: 1234
  STAGE1:
    BASE_LR: 0.00035
    CHECKPOINT_PERIOD: 120
    COSINE_MARGIN: 0.5
    COSINE_SCALE: 30
    EVAL_PERIOD: 10
    IMS_PER_BATCH: 64
    LOG_PERIOD: 50
    LR_MIN: 1e-06
    MAX_EPOCHS: 120
    MOMENTUM: 0.9
    OPTIMIZER_NAME: Adam
    WARMUP_EPOCHS: 5
    WARMUP_FACTOR: 0.01
    WARMUP_ITERS: 500
    WARMUP_LR_INIT: 1e-05
    WARMUP_METHOD: linear
    WEIGHT_DECAY: 0.0001
    WEIGHT_DECAY_BIAS: 0.0001
  STAGE2:
    BASE_LR: 1e-05
    BIAS_LR_FACTOR: 2
    CENTER_LOSS_WEIGHT: 0.0005
    CENTER_LR: 0.5
    CHECKPOINT_PERIOD: 5
    COSINE_MARGIN: 0.5
    COSINE_SCALE: 30
    EVAL_PERIOD: 5
    GAMMA: 0.1
    IMS_PER_BATCH: 64
    LARGE_FC_LR: False
    LOG_PERIOD: 50
    LR_MIN: 1.6e-05
    MAX_EPOCHS: 60
    MOMENTUM: 0.9
    OPTIMIZER_NAME: Adam
    STEPS: (30, 50)
    WARMUP_EPOCHS: 5
    WARMUP_FACTOR: 0.1
    WARMUP_ITERS: 10
    WARMUP_LR_INIT: 0.01
    WARMUP_METHOD: linear
    WEIGHT_DECAY: 0.0001
    WEIGHT_DECAY_BIAS: 0.0001
TEST:
  DIST_MAT: dist_mat.npy
  EVAL: True
  FEAT_NORM: yes
  IMS_PER_BATCH: 64
  NECK_FEAT: before
  RE_RANKING: False
  WEIGHT: 
2025-07-15 06:30:41,306 transreid.train INFO: start training
2025-07-15 06:30:41,310 transreid.train INFO: model: build_transformer(
  (classifier): Linear(in_features=768, out_features=558, bias=False)
  (classifier_proj): Linear(in_features=512, out_features=558, bias=False)
  (bottleneck): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bottleneck_proj): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (image_encoder): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (prompt_learner): PromptLearner()
  (text_encoder): TextEncoder(
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
2025-07-15 06:33:11,364 transreid.train INFO: Stage1 running time: 0:02:30.055255
2025-07-15 06:33:11,369 transreid.train INFO: start training
2025-07-15 06:33:16,192 transreid.train INFO: Epoch 1 done. Time per batch: 0.124[s] Speed: 516.3[samples/s]
2025-07-15 06:33:20,545 transreid.train INFO: Epoch 2 done. Time per batch: 0.128[s] Speed: 499.9[samples/s]
2025-07-15 06:33:25,134 transreid.train INFO: Epoch 3 done. Time per batch: 0.131[s] Speed: 488.1[samples/s]
2025-07-15 06:33:29,721 transreid.train INFO: Epoch 4 done. Time per batch: 0.124[s] Speed: 516.3[samples/s]
2025-07-15 06:33:34,284 transreid.train INFO: Epoch 5 done. Time per batch: 0.130[s] Speed: 491.0[samples/s]
2025-07-15 06:33:36,963 transreid.train INFO: Validation Results - Epoch: 5
2025-07-15 06:33:36,963 transreid.train INFO: mAP: 75.9%
2025-07-15 06:33:36,963 transreid.train INFO: CMC curve, Rank-1  :79.0%
2025-07-15 06:33:36,963 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:33:36,963 transreid.train INFO: CMC curve, Rank-10 :96.8%
2025-07-15 06:33:41,505 transreid.train INFO: Epoch 6 done. Time per batch: 0.126[s] Speed: 507.3[samples/s]
2025-07-15 06:33:46,100 transreid.train INFO: Epoch 7 done. Time per batch: 0.128[s] Speed: 501.5[samples/s]
2025-07-15 06:33:50,381 transreid.train INFO: Epoch 8 done. Time per batch: 0.122[s] Speed: 523.3[samples/s]
2025-07-15 06:33:54,993 transreid.train INFO: Epoch 9 done. Time per batch: 0.128[s] Speed: 499.6[samples/s]
2025-07-15 06:33:59,590 transreid.train INFO: Epoch 10 done. Time per batch: 0.131[s] Speed: 487.3[samples/s]
2025-07-15 06:34:01,662 transreid.train INFO: Validation Results - Epoch: 10
2025-07-15 06:34:01,662 transreid.train INFO: mAP: 78.4%
2025-07-15 06:34:01,662 transreid.train INFO: CMC curve, Rank-1  :80.6%
2025-07-15 06:34:01,662 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:34:01,662 transreid.train INFO: CMC curve, Rank-10 :100.0%
2025-07-15 06:34:06,142 transreid.train INFO: Epoch 11 done. Time per batch: 0.124[s] Speed: 515.7[samples/s]
2025-07-15 06:34:10,999 transreid.train INFO: Epoch 12 done. Time per batch: 0.135[s] Speed: 474.4[samples/s]
2025-07-15 06:34:15,419 transreid.train INFO: Epoch 13 done. Time per batch: 0.123[s] Speed: 521.3[samples/s]
2025-07-15 06:34:19,807 transreid.train INFO: Epoch 14 done. Time per batch: 0.122[s] Speed: 525.1[samples/s]
2025-07-15 06:34:23,914 transreid.train INFO: Epoch 15 done. Time per batch: 0.121[s] Speed: 529.9[samples/s]
2025-07-15 06:34:25,852 transreid.train INFO: Validation Results - Epoch: 15
2025-07-15 06:34:25,852 transreid.train INFO: mAP: 79.9%
2025-07-15 06:34:25,852 transreid.train INFO: CMC curve, Rank-1  :82.3%
2025-07-15 06:34:25,852 transreid.train INFO: CMC curve, Rank-5  :98.4%
2025-07-15 06:34:25,852 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:34:30,284 transreid.train INFO: Epoch 16 done. Time per batch: 0.126[s] Speed: 506.8[samples/s]
2025-07-15 06:34:34,517 transreid.train INFO: Epoch 17 done. Time per batch: 0.124[s] Speed: 514.1[samples/s]
2025-07-15 06:34:38,845 transreid.train INFO: Epoch 18 done. Time per batch: 0.124[s] Speed: 517.6[samples/s]
2025-07-15 06:34:43,331 transreid.train INFO: Epoch 19 done. Time per batch: 0.125[s] Speed: 513.7[samples/s]
2025-07-15 06:34:47,547 transreid.train INFO: Epoch 20 done. Time per batch: 0.120[s] Speed: 531.5[samples/s]
2025-07-15 06:34:49,625 transreid.train INFO: Validation Results - Epoch: 20
2025-07-15 06:34:49,625 transreid.train INFO: mAP: 78.7%
2025-07-15 06:34:49,625 transreid.train INFO: CMC curve, Rank-1  :79.0%
2025-07-15 06:34:49,625 transreid.train INFO: CMC curve, Rank-5  :95.2%
2025-07-15 06:34:49,625 transreid.train INFO: CMC curve, Rank-10 :100.0%
2025-07-15 06:34:53,897 transreid.train INFO: Epoch 21 done. Time per batch: 0.125[s] Speed: 510.9[samples/s]
2025-07-15 06:34:58,008 transreid.train INFO: Epoch 22 done. Time per batch: 0.121[s] Speed: 529.4[samples/s]
2025-07-15 06:35:02,314 transreid.train INFO: Epoch 23 done. Time per batch: 0.123[s] Speed: 520.3[samples/s]
2025-07-15 06:35:06,648 transreid.train INFO: Epoch 24 done. Time per batch: 0.120[s] Speed: 531.7[samples/s]
2025-07-15 06:35:10,959 transreid.train INFO: Epoch 25 done. Time per batch: 0.123[s] Speed: 519.6[samples/s]
2025-07-15 06:35:12,937 transreid.train INFO: Validation Results - Epoch: 25
2025-07-15 06:35:12,937 transreid.train INFO: mAP: 81.1%
2025-07-15 06:35:12,937 transreid.train INFO: CMC curve, Rank-1  :79.0%
2025-07-15 06:35:12,937 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:35:12,937 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:35:17,466 transreid.train INFO: Epoch 26 done. Time per batch: 0.129[s] Speed: 495.7[samples/s]
2025-07-15 06:35:22,066 transreid.train INFO: Epoch 27 done. Time per batch: 0.128[s] Speed: 500.9[samples/s]
2025-07-15 06:35:26,825 transreid.train INFO: Epoch 28 done. Time per batch: 0.129[s] Speed: 497.6[samples/s]
2025-07-15 06:35:31,473 transreid.train INFO: Epoch 29 done. Time per batch: 0.129[s] Speed: 495.7[samples/s]
2025-07-15 06:35:35,965 transreid.train INFO: Epoch 30 done. Time per batch: 0.132[s] Speed: 484.6[samples/s]
2025-07-15 06:35:38,168 transreid.train INFO: Validation Results - Epoch: 30
2025-07-15 06:35:38,168 transreid.train INFO: mAP: 81.5%
2025-07-15 06:35:38,168 transreid.train INFO: CMC curve, Rank-1  :85.5%
2025-07-15 06:35:38,168 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:35:38,169 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:35:42,593 transreid.train INFO: Epoch 31 done. Time per batch: 0.123[s] Speed: 521.9[samples/s]
2025-07-15 06:35:46,925 transreid.train INFO: Epoch 32 done. Time per batch: 0.120[s] Speed: 532.0[samples/s]
2025-07-15 06:35:51,199 transreid.train INFO: Epoch 33 done. Time per batch: 0.126[s] Speed: 509.2[samples/s]
2025-07-15 06:35:55,361 transreid.train INFO: Epoch 34 done. Time per batch: 0.119[s] Speed: 538.2[samples/s]
2025-07-15 06:35:59,755 transreid.train INFO: Epoch 35 done. Time per batch: 0.122[s] Speed: 524.4[samples/s]
2025-07-15 06:36:01,875 transreid.train INFO: Validation Results - Epoch: 35
2025-07-15 06:36:01,876 transreid.train INFO: mAP: 81.4%
2025-07-15 06:36:01,876 transreid.train INFO: CMC curve, Rank-1  :82.3%
2025-07-15 06:36:01,876 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:36:01,876 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:36:06,411 transreid.train INFO: Epoch 36 done. Time per batch: 0.129[s] Speed: 495.4[samples/s]
2025-07-15 06:36:11,029 transreid.train INFO: Epoch 37 done. Time per batch: 0.132[s] Speed: 485.1[samples/s]
2025-07-15 06:36:15,565 transreid.train INFO: Epoch 38 done. Time per batch: 0.126[s] Speed: 508.0[samples/s]
2025-07-15 06:36:19,880 transreid.train INFO: Epoch 39 done. Time per batch: 0.120[s] Speed: 534.1[samples/s]
2025-07-15 06:36:24,357 transreid.train INFO: Epoch 40 done. Time per batch: 0.124[s] Speed: 514.7[samples/s]
2025-07-15 06:36:26,189 transreid.train INFO: Validation Results - Epoch: 40
2025-07-15 06:36:26,189 transreid.train INFO: mAP: 81.5%
2025-07-15 06:36:26,189 transreid.train INFO: CMC curve, Rank-1  :83.9%
2025-07-15 06:36:26,189 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:36:26,189 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:36:30,746 transreid.train INFO: Epoch 41 done. Time per batch: 0.126[s] Speed: 507.0[samples/s]
2025-07-15 06:36:34,983 transreid.train INFO: Epoch 42 done. Time per batch: 0.121[s] Speed: 528.7[samples/s]
2025-07-15 06:36:39,427 transreid.train INFO: Epoch 43 done. Time per batch: 0.123[s] Speed: 518.6[samples/s]
2025-07-15 06:36:43,978 transreid.train INFO: Epoch 44 done. Time per batch: 0.130[s] Speed: 492.3[samples/s]
2025-07-15 06:36:48,297 transreid.train INFO: Epoch 45 done. Time per batch: 0.120[s] Speed: 533.5[samples/s]
2025-07-15 06:36:50,219 transreid.train INFO: Validation Results - Epoch: 45
2025-07-15 06:36:50,220 transreid.train INFO: mAP: 81.8%
2025-07-15 06:36:50,220 transreid.train INFO: CMC curve, Rank-1  :83.9%
2025-07-15 06:36:50,220 transreid.train INFO: CMC curve, Rank-5  :98.4%
2025-07-15 06:36:50,220 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:36:54,717 transreid.train INFO: Epoch 46 done. Time per batch: 0.128[s] Speed: 499.4[samples/s]
2025-07-15 06:36:59,048 transreid.train INFO: Epoch 47 done. Time per batch: 0.120[s] Speed: 532.1[samples/s]
2025-07-15 06:37:03,439 transreid.train INFO: Epoch 48 done. Time per batch: 0.125[s] Speed: 510.2[samples/s]
2025-07-15 06:37:07,610 transreid.train INFO: Epoch 49 done. Time per batch: 0.119[s] Speed: 537.1[samples/s]
2025-07-15 06:37:11,890 transreid.train INFO: Epoch 50 done. Time per batch: 0.122[s] Speed: 523.4[samples/s]
2025-07-15 06:37:13,743 transreid.train INFO: Validation Results - Epoch: 50
2025-07-15 06:37:13,743 transreid.train INFO: mAP: 81.8%
2025-07-15 06:37:13,743 transreid.train INFO: CMC curve, Rank-1  :83.9%
2025-07-15 06:37:13,743 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:37:13,743 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:37:18,026 transreid.train INFO: Epoch 51 done. Time per batch: 0.122[s] Speed: 524.3[samples/s]
2025-07-15 06:37:22,701 transreid.train INFO: Epoch 52 done. Time per batch: 0.130[s] Speed: 492.9[samples/s]
2025-07-15 06:37:27,038 transreid.train INFO: Epoch 53 done. Time per batch: 0.120[s] Speed: 531.3[samples/s]
2025-07-15 06:37:31,122 transreid.train INFO: Epoch 54 done. Time per batch: 0.120[s] Speed: 532.8[samples/s]
2025-07-15 06:37:35,348 transreid.train INFO: Epoch 55 done. Time per batch: 0.124[s] Speed: 515.0[samples/s]
2025-07-15 06:37:37,195 transreid.train INFO: Validation Results - Epoch: 55
2025-07-15 06:37:37,196 transreid.train INFO: mAP: 81.6%
2025-07-15 06:37:37,196 transreid.train INFO: CMC curve, Rank-1  :83.9%
2025-07-15 06:37:37,196 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:37:37,196 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:37:41,668 transreid.train INFO: Epoch 56 done. Time per batch: 0.124[s] Speed: 516.3[samples/s]
2025-07-15 06:37:45,893 transreid.train INFO: Epoch 57 done. Time per batch: 0.124[s] Speed: 515.1[samples/s]
2025-07-15 06:37:50,238 transreid.train INFO: Epoch 58 done. Time per batch: 0.121[s] Speed: 530.3[samples/s]
2025-07-15 06:37:54,590 transreid.train INFO: Epoch 59 done. Time per batch: 0.121[s] Speed: 529.5[samples/s]
2025-07-15 06:37:59,052 transreid.train INFO: Epoch 60 done. Time per batch: 0.124[s] Speed: 516.4[samples/s]
2025-07-15 06:38:00,832 transreid.train INFO: Validation Results - Epoch: 60
2025-07-15 06:38:00,832 transreid.train INFO: mAP: 81.7%
2025-07-15 06:38:00,832 transreid.train INFO: CMC curve, Rank-1  :83.9%
2025-07-15 06:38:00,832 transreid.train INFO: CMC curve, Rank-5  :96.8%
2025-07-15 06:38:00,832 transreid.train INFO: CMC curve, Rank-10 :98.4%
2025-07-15 06:38:00,843 transreid.train INFO: Total running time: 0:04:49.061300
